{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXqWQpElW/HMAT5dcWcQsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imyoungchae/Tensorflow_study/blob/main/tensorflow6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN(Convolution Neural network)를 활용한 image Classification"
      ],
      "metadata": {
        "id": "IBeBSZewfQbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "i2iey9LRfdXz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4D46RotaOgn"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "ke_yy8ABffXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'cats_vs_dogs'\n",
        "\n",
        "# 처음 80%의 데이터만 사용\n",
        "train_dataset = tfds.load(name=dataset_name, split='train[:80%]')\n",
        "\n",
        "# 최근 20%의 데이터만 사용\n",
        "valid_dataset = tfds.load(name=dataset_name, split='train[80%:]')"
      ],
      "metadata": {
        "id": "3sPkq8O7fiCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시험에서 요구하는 전처리 요구 조건\n",
        "1. 이미지 정규화 (Nomalization)\n",
        "2. 이미지 사이즈 맞추기 (244x244)\n",
        "3. image(x),label(y)를 분할"
      ],
      "metadata": {
        "id": "aC4gWshOfvVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "    # x, y 데이터를 정의합니다.\n",
        "    x = data['image']\n",
        "    y = data['label']\n",
        "    # image 정규화(Normalization)\n",
        "    x = x / 255\n",
        "    # 사이즈를 (224, 224)로 변환합니다.\n",
        "    x = tf.image.resize(x, size=(224, 224))\n",
        "    # x, y  데이터를 return 합니다.\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "8HGpeyZlfs9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만든 전처리 함수(preprocessing)을 dataset에 mapping하고 batch_size 지정"
      ],
      "metadata": {
        "id": "3LwdjiZpf-1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32"
      ],
      "metadata": {
        "id": "wwanVHU6f9Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_dataset.map(preprocess).batch(batch_size)\n",
        "valid_data = valid_dataset.map(preprocess).batch(batch_size)"
      ],
      "metadata": {
        "id": "unpSPZdFf9za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential"
      ],
      "metadata": {
        "id": "AZ6Q6sMJgG_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 Modeling을 할 차례\n",
        "1. input_shape는 244x244 컬러사진인 (244,244,3)으로 지정\n",
        "2. transfer learning 기법을 통해 VGG16 모델을 활용한 전이학습 모델 완성\n",
        "3. 출력층은 class 갯수 2개의 뉴런 요구"
      ],
      "metadata": {
        "id": "Lrwl2_DUgJdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "transfer_model.trainable=False # Freeze: 윗단계에서 학습이 일어나지 않도록"
      ],
      "metadata": {
        "id": "Z9DedRbUgbtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b849d2b-8262-4ae7-cf81-3291c8526b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    transfer_model,\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax'), # 개, 고양이 분류니까 Dense 2\n",
        "])"
      ],
      "metadata": {
        "id": "SRnoqRwdgcx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1crxl3OIgd77",
        "outputId": "7f36cec8-3834-4ede-a799-3f94ab2d2f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               12845568  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,626,178\n",
            "Trainable params: 12,911,490\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile"
      ],
      "metadata": {
        "id": "Tf2fS4LygjFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "k3MhF_UVglGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ModelCheckpoint"
      ],
      "metadata": {
        "id": "P0Mqo3WTgnrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)"
      ],
      "metadata": {
        "id": "e59Y2oivgquR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit"
      ],
      "metadata": {
        "id": "u3l1qg9FgsL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data,\n",
        "          validation_data=(valid_data),\n",
        "          epochs=10,\n",
        "          callbacks=[checkpoint],\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9oMC6o1gtrl",
        "outputId": "ddadc68c-fd94-4908-fe85-e90ac670ae1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 60/582 [==>...........................] - ETA: 2:36 - loss: 0.1296 - acc: 0.9505"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Weights"
      ],
      "metadata": {
        "id": "RQ-nBsXxgufp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint 를 저장한 파일명을 입력\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "YRiH7v4sgyk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}